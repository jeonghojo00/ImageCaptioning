{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1. ImgCaptioning_EncoderSearching",
      "provenance": [],
      "collapsed_sections": [
        "xPTatRtLltku",
        "HIlLGMxtg8E0",
        "CoAhxf8OiywC"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOUQdbdHOFUZK8P1j5n18KS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeonghojo00/ImageCaptioning/blob/main/1_ImgCaptioning_EncoderSearching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITQKi60ecc7e"
      },
      "source": [
        "#0. Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9RrduYbcmcE"
      },
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydMo8oIYcsPa",
        "outputId": "4fae21c8-fd63-4c11-d5bf-459fed924a15"
      },
      "source": [
        "# Change directory to the package folder\n",
        "%cd '/content/drive/MyDrive/Colab Notebooks/ImageCaptioning/'\n",
        "# Verify the contents of the current folder\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/ImageCaptioning\n",
            "checkpoint\t\t      license.txt\t\t  pycocotools\n",
            "code\t\t\t      load_data.py\t\t  README.md\n",
            "cs7643-final-project\t      lstm_decoder.py\t\t  resize_image.py\n",
            "custom_caption_eval.py\t      main.py\t\t\t  resnet.py\n",
            "data\t\t\t      model\t\t\t  show_attend_tell.py\n",
            "data_loader.py\t\t      models\t\t\t  split_caption.py\n",
            "efficientnet.py\t\t      models.py\t\t\t  util\n",
            "experiments\t\t      nic_decoder_ResNet101.ckpt  utils.py\n",
            "get_google_word2vec_model.sh  nic_encoder_ResNet101.ckpt  vgg.py\n",
            "get_stanford_models.sh\t      pretraining.py\t\t  vocab.pkl\n",
            "inception.py\t\t      __pycache__\t\t  vocabulary.py\n",
            "learned_models\t\t      pycocoevalcap\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi74KD1Y2RmM"
      },
      "source": [
        "import sys\n",
        "import subprocess\n",
        "import pkg_resources\n",
        "\n",
        "required = {'efficientnet_pytorch', 'timm', 'tqdm', 'torch', 'torchvision'}\n",
        "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
        "missing = required - installed\n",
        "\n",
        "if missing:\n",
        "    python = sys.executable\n",
        "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNiNq3zvv_bk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38317596-20f8-4a73-9aba-32b8ccf180d5"
      },
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import nltk\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torchvision import transforms\n",
        "\n",
        "import torchvision.models as models\n",
        "from model import (\n",
        "    encoderCNN,\n",
        "    decoderRNN\n",
        ")\n",
        "from load_data import *\n",
        "from resize_image import *\n",
        "from split_caption import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZsHc0l8wA4q"
      },
      "source": [
        "# Define data folder\n",
        "image_dir = './data/flickr8k/Images' # Original images folder\n",
        "caption_path = './data/flickr8k/captions.txt' # Original caption file with path\n",
        "\n",
        "train_image_dir = './data/resized_flickr8k/train/Images' # Resized train images folder\n",
        "val_image_dir = './data/resized_flickr8k/val/Images' # Resized validation images folder\n",
        "test_image_dir = './data/resized_flickr8k/test/Images' # Resized test images folder\n",
        "train_caption_path = \"./data/resized_flickr8k/train/captions.txt\" # Resized train images' captions\n",
        "val_caption_path = \"./data/resized_flickr8k/val/captions.txt\" # Resized validation images' captions\n",
        "test_caption_path = \"./data/resized_flickr8k/test/captions.txt\" # Resized test images' captions\n",
        "\n",
        "# Run for 299x299 resized images\n",
        "\n",
        "train299_image_dir = './data/resized_flickr8k_299/train/Images' # Resized train images folder\n",
        "val299_image_dir = './data/resized_flickr8k_299/val/Images' # Resized validation images folder\n",
        "test299_image_dir = './data/resized_flickr8k_299/test/Images' # Resized test images folder\n",
        "train299_caption_path = \"./data/resized_flickr8k_299/train/captions.txt\" # Resized train images' captions\n",
        "val299_caption_path = \"./data/resized_flickr8k_299/val/captions.txt\" # Resized validation images' captions\n",
        "test299_caption_path = \"./data/resized_flickr8k_299/test/captions.txt\" # Resized test images' captions\n",
        "\n",
        "\n",
        "\n",
        "resized_image = [299,299] # Resized image size 299 for inception and 256 for the others\n",
        "num_train_images = 6000\n",
        "num_val_images = 1000\n",
        "\n",
        "vocab_path = \"./vocab.pkl\" # vocabulary file\n",
        "word_threshold = 4 # Minimum occurrances of words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKHVQUYlc7ZP"
      },
      "source": [
        "#1. Preprocess Images and Captions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PztJTwzEbevs"
      },
      "source": [
        "## Preprocess images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3xyDyoB9oxn"
      },
      "source": [
        "resizeImage_required = False\n",
        "if resizeImage_required == True:\n",
        "    save_resized_images(image_dir, train_image_dir, val_image_dir, test_image_dir, num_train_images, num_val_images, resize_image=resized_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkBSBKWKDtdv"
      },
      "source": [
        "## Preprocess captions for vocab dictionary and caption divisions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v49kh8ncb-Ow"
      },
      "source": [
        "splitCaption_required = True\n",
        "\n",
        "if splitCaption_required == True:\n",
        "    split_caption(caption_path, train299_caption_path, val299_caption_path, test299_caption_path, vocab_path, num_train_images, num_val_images, word_threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybg10OqBRhCv",
        "outputId": "c2fb3f00-d739-424d-8063-6d2fde7143a9"
      },
      "source": [
        "# Number of Traning data\n",
        "!wc -l ./data/resized_flickr8k_299/train/captions.txt\n",
        "# Number of Validation data\n",
        "!wc -l ./data/resized_flickr8k_299/val/captions.txt\n",
        "# Number of Testing data\n",
        "!wc -l ./data/resized_flickr8k_299/test/captions.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63556 ./data/resized_flickr8k_299/train/captions.txt\n",
            "10000 ./data/resized_flickr8k_299/val/captions.txt\n",
            "10910 ./data/resized_flickr8k_299/test/captions.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpC1UD81meOZ"
      },
      "source": [
        "#2. Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3baowuHJqbY"
      },
      "source": [
        "def load_encoder(encoder_name, embed_size):\n",
        "    encoder = None\n",
        "    if encoder_name == 'ResNet152':\n",
        "        encoder = encoderCNN.ResNet152(embed_size)\n",
        "    elif encoder_name == 'Efficientnet':\n",
        "        encoder = encoderCNN.Efficientnet(embed_size)\n",
        "    elif encoder_name == \"DenseNet161\":\n",
        "        encoder = encoderCNN.DenseNet161(embed_size)\n",
        "    elif encoder_name == \"InceptionV3\":\n",
        "        encoder = encoderCNN.InceptionV3(embed_size)\n",
        "    elif encoder_name == \"GoogleNet\":\n",
        "        encoder = encoderCNN.GoogleNet(embed_size)\n",
        "    elif encoder_name == \"MobileNetV3\":\n",
        "        encoder = encoderCNN.MobileNetV3(embed_size)\n",
        "    elif encoder_name == \"ResNeXt101\":\n",
        "        encoder = encoderCNN.ResNeXt101(embed_size)\n",
        "    elif encoder_name == \"WideResNet101\":\n",
        "        encoder = encoderCNN.WideResNet101(embed_size)\n",
        "    elif encoder_name == \"MNASNet\":\n",
        "        encoder = encoderCNN.MNASNet(embed_size)\n",
        "    elif encoder_name == \"ShuffleNetV2\":\n",
        "        encoder = encoderCNN.ShuffleNetV2(embed_size)\n",
        "    elif encoder_name == \"SqueezeNet\":\n",
        "        encoder = encoderCNN.SqueezeNet(embed_size)\n",
        "    \n",
        "    return encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfbAZRv5hDSy"
      },
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "models_path = \"./learned_models/\" # model path that learned models will be saved\n",
        "crop_size = 224 #299 if encoder==\"InceptionV3\"\n",
        "\n",
        "vocab_path = \"./vocab.pkl\" # Vocabulary path that is preprocessed\n",
        "\n",
        "# Make a directory that a learned model will be saved\n",
        "if not os.path.exists(models_path):\n",
        "    os.makedirs(models_path)\n",
        "\n",
        "# Load Vocabulary dictionary (Vocabulary class needs to be defined first)\n",
        "with open(vocab_path, 'rb') as f:\n",
        "    vocab = pickle.load(f)\n",
        "\n",
        "# Make transforms for training, validating, and testing the model\n",
        "train_transform = transforms.Compose([ \n",
        "    transforms.RandomCrop(crop_size),\n",
        "    transforms.RandomHorizontalFlip(), \n",
        "    transforms.ToTensor(), \n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "val_transform = transforms.Compose([ \n",
        "    transforms.Resize(crop_size), \n",
        "    transforms.ToTensor(), \n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "test_transform = transforms.Compose([ \n",
        "    transforms.Resize(crop_size), \n",
        "    transforms.ToTensor(), \n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "batch_size = 128\n",
        "num_workers = 2\n",
        "\n",
        "# Get the dataloaders\n",
        "train_data_loader = get_loader(train299_image_dir, train299_caption_path, vocab, train_transform, batch_size, shuffle=True, num_workers=num_workers, testing=False) \n",
        "val_data_loader = get_loader(val299_image_dir, val299_caption_path, vocab, val_transform, batch_size, shuffle=False, num_workers=num_workers, testing=False)\n",
        "test_data_loader = get_loader(test299_image_dir, test299_caption_path, vocab, test_transform, batch_size, shuffle=False, num_workers=num_workers, testing=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRSeUE1oJeL-",
        "outputId": "ef3a1c18-2ef4-4f66-b190-ba93a94b7431"
      },
      "source": [
        "train_data_loader.dataset[0][0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 299, 299])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVniZiUSSDUC"
      },
      "source": [
        "# Model Hyperparamter\n",
        "embed_size = 256 # Embedding size for output of encoder and input of decoder\n",
        "hidden_size = 512 # LSTM hidden states\n",
        "num_layers = 1 # Number of layers of LSTM\n",
        "\n",
        "# Declare a decoder\n",
        "decoder = decoderRNN.DecoderLSTM(embed_size, hidden_size, len(vocab), num_layers).to(device)\n",
        "\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "log_step = 20 # Number of steps to show a log for each batch\n",
        "save_step = 1000 # Number of steps to save the learned model\n",
        "\n",
        "# Set loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bM7pdCPJPsC"
      },
      "source": [
        "'''\n",
        "encoder_list = ['ResNet152',\n",
        "                'Efficientnet',\n",
        "                'DenseNet161',\n",
        "                'GoogleNet',\n",
        "                'MobileNetV3',\n",
        "                'ResNeXt101',\n",
        "                'WideResNet101',\n",
        "                'MNASNet',\n",
        "                'ShuffleNetV2',\n",
        "                'SqueezeNet']\n",
        "'''\n",
        "encoder_list = ['InceptionV3']\n",
        "# InceptionV3 needs input_size of 299\n",
        "# InceptionV3 needs to be processed separately"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O63LJY2TUM9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdbb5b27-db24-4c62-f7c4-8ab6deb6ec99"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "start_time = time.time()\n",
        "loss_dict = dict()\n",
        "loss_dict['train'] = dict()\n",
        "loss_dict['val'] = dict()\n",
        "perplexity_dict = dict()\n",
        "perplexity_dict['train'] = dict()\n",
        "perplexity_dict['val'] = dict()\n",
        "\n",
        "for encoder_name in encoder_list:\n",
        "    encoder = load_encoder(encoder_name, embed_size).to(device)\n",
        "    each_model_path = os.path.join(models_path, encoder_name)\n",
        "    if not os.path.exists(each_model_path):\n",
        "        os.makedirs(each_model_path)\n",
        "    \n",
        "    if encoder_name == \"ResNet152\":\n",
        "        params = list(decoder.parameters()) + list(encoder.linear.parameters()) + list(encoder.bn.parameters())   \n",
        "    else:\n",
        "        params = list(decoder.parameters()) + list(encoder.parameters()) \n",
        "    optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
        "        \n",
        "    for epoch in range(num_epochs):\n",
        "        # Train\n",
        "        print(\"[ Training ]\")\n",
        "        total_loss = 0\n",
        "        total_count = 0\n",
        "        total_step = len(train_data_loader)\n",
        "        for i, (images, captions, lengths) in enumerate(train_data_loader):\n",
        "            images = images.to(device)\n",
        "            captions = captions.to(device)\n",
        "            targets = pack_padded_sequence(captions, lengths, batch_first=True)[0]\n",
        "\n",
        "            # Training by forward and backward\n",
        "            features = encoder(images)\n",
        "            if encoder_name == \"InceptionV3\":\n",
        "                features = features.logits\n",
        "            outputs = decoder(features, captions, lengths)\n",
        "            loss = criterion(outputs, targets)\n",
        "            decoder.zero_grad()\n",
        "            encoder.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculate loss\n",
        "            total_loss += loss.item()\n",
        "            total_count += images.shape[0]\n",
        "\n",
        "            # Print a log\n",
        "            avg_loss = total_loss / total_count\n",
        "            perplexity = np.exp(loss.item())\n",
        "\n",
        "            if epoch in loss_dict['train']:\n",
        "                loss_dict['train'][epoch].append(avg_loss)\n",
        "                perplexity_dict['train'][epoch].append(perplexity)\n",
        "            else:\n",
        "                loss_dict['train'][epoch] = list()\n",
        "                perplexity_dict['train'][epoch] = list()\n",
        "                loss_dict['train'][epoch].append(avg_loss)\n",
        "                perplexity_dict['train'][epoch].append(perplexity)\n",
        "\n",
        "            if i % log_step == 0:\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Average Loss: {:.4f}, Perplexity: {:5.4f}, Elapsed time: {:.4f}s'\n",
        "                      .format(epoch, num_epochs, i, total_step, avg_loss, perplexity, time.time() - start_time))\n",
        "\n",
        "        # Save learned models\n",
        "        torch.save(decoder.state_dict(), os.path.join(each_model_path, f'decoder-{epoch + 1}.ckpt'))\n",
        "        torch.save(encoder.state_dict(), os.path.join(each_model_path, f'encoder-{epoch + 1}.ckpt'))\n",
        "        print(f\"Model saved: {os.path.join(each_model_path, f'decoder-{epoch + 1}.ckpt')}\")\n",
        "        print(f\"Model saved: {os.path.join(each_model_path, f'encoder-{epoch + 1}.ckpt')}\")\n",
        "\n",
        "        # Validate\n",
        "        print(\"[ Validation ]\")\n",
        "        total_loss = 0\n",
        "        total_count = 0\n",
        "        total_step = len(val_data_loader)\n",
        "        with torch.no_grad():\n",
        "            for i, (images, captions, lengths) in enumerate(val_data_loader):\n",
        "                images = images.to(device)\n",
        "                captions = captions.to(device)\n",
        "                targets = pack_padded_sequence(captions, lengths, batch_first=True)[0]\n",
        "\n",
        "                # Only Forward\n",
        "                features = encoder(images)\n",
        "                if encoder_name == \"InceptionV3\":\n",
        "                    features = features.logits\n",
        "                outputs = decoder(features, captions, lengths)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "                # Calculate the loss\n",
        "                total_loss += loss.item()\n",
        "                total_count += images.shape[0]\n",
        "\n",
        "                # Print the log\n",
        "                avg_loss = total_loss / total_count\n",
        "                perplexity = np.exp(loss.item())\n",
        "\n",
        "                if epoch in loss_dict['val']:\n",
        "                    loss_dict['val'][epoch].append(avg_loss)\n",
        "                    perplexity_dict['val'][epoch].append(perplexity)\n",
        "                else:\n",
        "                    loss_dict['val'][epoch] = list()\n",
        "                    perplexity_dict['val'][epoch] = list()\n",
        "                    loss_dict['val'][epoch].append(avg_loss)\n",
        "                    perplexity_dict['val'][epoch].append(perplexity)\n",
        "\n",
        "                if i % log_step == 0:\n",
        "                    print('Epoch [{}/{}], Step [{}/{}], Average Loss: {:.4f}, Perplexity: {:5.4f}, Elapsed time: {:.4f}s'\n",
        "                          .format(epoch, num_epochs, i, total_step, avg_loss, perplexity, time.time() - start_time))\n",
        "\n",
        "    # Save loss and perplexity as pickle files\n",
        "    loss_path = os.path.join(each_model_path, \"loss.pkl\")\n",
        "    with open(loss_path, 'wb') as f:\n",
        "        pickle.dump(loss_dict, f)\n",
        "\n",
        "    perp_path = os.path.join(each_model_path, \"perplexity.pkl\")\n",
        "    with open(perp_path, 'wb') as f:\n",
        "        pickle.dump(perplexity_dict, f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ Training ]\n",
            "Epoch [0/10], Step [0/497], Average Loss: 0.0250, Perplexity: 24.5903, Elapsed time: 1.5747s\n",
            "Epoch [0/10], Step [20/497], Average Loss: 0.0230, Perplexity: 14.4718, Elapsed time: 9.6565s\n",
            "Epoch [0/10], Step [40/497], Average Loss: 0.0222, Perplexity: 13.9485, Elapsed time: 17.7957s\n",
            "Epoch [0/10], Step [60/497], Average Loss: 0.0219, Perplexity: 16.8395, Elapsed time: 25.8841s\n",
            "Epoch [0/10], Step [80/497], Average Loss: 0.0217, Perplexity: 15.6737, Elapsed time: 34.0967s\n",
            "Epoch [0/10], Step [100/497], Average Loss: 0.0215, Perplexity: 13.7893, Elapsed time: 42.1262s\n",
            "Epoch [0/10], Step [120/497], Average Loss: 0.0214, Perplexity: 14.4820, Elapsed time: 50.2470s\n",
            "Epoch [0/10], Step [140/497], Average Loss: 0.0213, Perplexity: 12.3257, Elapsed time: 58.4757s\n",
            "Epoch [0/10], Step [160/497], Average Loss: 0.0212, Perplexity: 12.9532, Elapsed time: 66.5621s\n",
            "Epoch [0/10], Step [180/497], Average Loss: 0.0212, Perplexity: 14.6120, Elapsed time: 74.4760s\n",
            "Epoch [0/10], Step [200/497], Average Loss: 0.0211, Perplexity: 13.1291, Elapsed time: 82.4825s\n",
            "Epoch [0/10], Step [220/497], Average Loss: 0.0211, Perplexity: 14.4277, Elapsed time: 90.4966s\n",
            "Epoch [0/10], Step [240/497], Average Loss: 0.0210, Perplexity: 14.0312, Elapsed time: 98.8737s\n",
            "Epoch [0/10], Step [260/497], Average Loss: 0.0210, Perplexity: 14.6219, Elapsed time: 107.1046s\n",
            "Epoch [0/10], Step [280/497], Average Loss: 0.0209, Perplexity: 12.5703, Elapsed time: 115.1955s\n",
            "Epoch [0/10], Step [300/497], Average Loss: 0.0209, Perplexity: 13.3865, Elapsed time: 123.4462s\n",
            "Epoch [0/10], Step [320/497], Average Loss: 0.0208, Perplexity: 12.2350, Elapsed time: 131.5816s\n",
            "Epoch [0/10], Step [340/497], Average Loss: 0.0207, Perplexity: 12.7676, Elapsed time: 139.7389s\n",
            "Epoch [0/10], Step [360/497], Average Loss: 0.0207, Perplexity: 12.5767, Elapsed time: 147.8133s\n",
            "Epoch [0/10], Step [380/497], Average Loss: 0.0207, Perplexity: 13.1218, Elapsed time: 156.0977s\n",
            "Epoch [0/10], Step [400/497], Average Loss: 0.0206, Perplexity: 14.0094, Elapsed time: 164.2419s\n",
            "Epoch [0/10], Step [420/497], Average Loss: 0.0206, Perplexity: 12.3176, Elapsed time: 172.4757s\n",
            "Epoch [0/10], Step [440/497], Average Loss: 0.0205, Perplexity: 12.6081, Elapsed time: 180.5706s\n",
            "Epoch [0/10], Step [460/497], Average Loss: 0.0205, Perplexity: 11.8579, Elapsed time: 188.7231s\n",
            "Epoch [0/10], Step [480/497], Average Loss: 0.0204, Perplexity: 11.4609, Elapsed time: 196.8791s\n",
            "Model saved: ./learned_models/InceptionV3/decoder-1.ckpt\n",
            "Model saved: ./learned_models/InceptionV3/encoder-1.ckpt\n",
            "[ Validation ]\n",
            "Epoch [0/10], Step [0/79], Average Loss: 0.0211, Perplexity: 14.8142, Elapsed time: 204.8971s\n",
            "Epoch [0/10], Step [20/79], Average Loss: 0.0216, Perplexity: 17.5438, Elapsed time: 342.9927s\n",
            "Epoch [0/10], Step [40/79], Average Loss: 0.0217, Perplexity: 17.1858, Elapsed time: 471.7282s\n",
            "Epoch [0/10], Step [60/79], Average Loss: 0.0216, Perplexity: 14.9064, Elapsed time: 479.3555s\n",
            "[ Training ]\n",
            "Epoch [1/10], Step [0/497], Average Loss: 0.0185, Perplexity: 10.7269, Elapsed time: 486.9275s\n",
            "Epoch [1/10], Step [20/497], Average Loss: 0.0186, Perplexity: 9.8302, Elapsed time: 495.2422s\n",
            "Epoch [1/10], Step [40/497], Average Loss: 0.0185, Perplexity: 11.7099, Elapsed time: 503.4982s\n",
            "Epoch [1/10], Step [60/497], Average Loss: 0.0186, Perplexity: 10.6610, Elapsed time: 511.4840s\n",
            "Epoch [1/10], Step [80/497], Average Loss: 0.0186, Perplexity: 11.1651, Elapsed time: 519.4985s\n",
            "Epoch [1/10], Step [100/497], Average Loss: 0.0185, Perplexity: 10.6930, Elapsed time: 527.7601s\n",
            "Epoch [1/10], Step [120/497], Average Loss: 0.0185, Perplexity: 10.9043, Elapsed time: 535.8734s\n",
            "Epoch [1/10], Step [140/497], Average Loss: 0.0185, Perplexity: 9.9155, Elapsed time: 543.9063s\n",
            "Epoch [1/10], Step [160/497], Average Loss: 0.0185, Perplexity: 10.2804, Elapsed time: 552.0173s\n",
            "Epoch [1/10], Step [180/497], Average Loss: 0.0185, Perplexity: 11.0204, Elapsed time: 560.2101s\n",
            "Epoch [1/10], Step [200/497], Average Loss: 0.0184, Perplexity: 9.2386, Elapsed time: 568.5932s\n",
            "Epoch [1/10], Step [220/497], Average Loss: 0.0184, Perplexity: 10.2838, Elapsed time: 576.6339s\n",
            "Epoch [1/10], Step [240/497], Average Loss: 0.0184, Perplexity: 9.5003, Elapsed time: 584.7385s\n",
            "Epoch [1/10], Step [260/497], Average Loss: 0.0184, Perplexity: 11.0166, Elapsed time: 592.8313s\n",
            "Epoch [1/10], Step [280/497], Average Loss: 0.0184, Perplexity: 10.3520, Elapsed time: 601.0269s\n",
            "Epoch [1/10], Step [300/497], Average Loss: 0.0183, Perplexity: 9.7497, Elapsed time: 608.9996s\n",
            "Epoch [1/10], Step [320/497], Average Loss: 0.0183, Perplexity: 10.6897, Elapsed time: 617.0246s\n",
            "Epoch [1/10], Step [340/497], Average Loss: 0.0183, Perplexity: 9.5156, Elapsed time: 625.2410s\n",
            "Epoch [1/10], Step [360/497], Average Loss: 0.0183, Perplexity: 10.5103, Elapsed time: 633.5371s\n",
            "Epoch [1/10], Step [380/497], Average Loss: 0.0182, Perplexity: 9.9613, Elapsed time: 641.5383s\n",
            "Epoch [1/10], Step [400/497], Average Loss: 0.0182, Perplexity: 10.3446, Elapsed time: 650.0414s\n",
            "Epoch [1/10], Step [420/497], Average Loss: 0.0182, Perplexity: 9.7016, Elapsed time: 658.1791s\n",
            "Epoch [1/10], Step [440/497], Average Loss: 0.0182, Perplexity: 9.3575, Elapsed time: 666.3858s\n",
            "Epoch [1/10], Step [460/497], Average Loss: 0.0182, Perplexity: 8.7752, Elapsed time: 674.6196s\n",
            "Epoch [1/10], Step [480/497], Average Loss: 0.0181, Perplexity: 9.1410, Elapsed time: 682.9028s\n",
            "Model saved: ./learned_models/InceptionV3/decoder-2.ckpt\n",
            "Model saved: ./learned_models/InceptionV3/encoder-2.ckpt\n",
            "[ Validation ]\n",
            "Epoch [1/10], Step [0/79], Average Loss: 0.0206, Perplexity: 13.9947, Elapsed time: 690.6484s\n",
            "Epoch [1/10], Step [20/79], Average Loss: 0.0211, Perplexity: 16.7742, Elapsed time: 698.7853s\n",
            "Epoch [1/10], Step [40/79], Average Loss: 0.0212, Perplexity: 16.3149, Elapsed time: 706.9195s\n",
            "Epoch [1/10], Step [60/79], Average Loss: 0.0212, Perplexity: 13.7476, Elapsed time: 714.6522s\n",
            "[ Training ]\n",
            "Epoch [2/10], Step [0/497], Average Loss: 0.0170, Perplexity: 8.7947, Elapsed time: 722.2650s\n",
            "Epoch [2/10], Step [20/497], Average Loss: 0.0167, Perplexity: 7.9796, Elapsed time: 730.1472s\n",
            "Epoch [2/10], Step [40/497], Average Loss: 0.0167, Perplexity: 8.7441, Elapsed time: 738.3115s\n",
            "Epoch [2/10], Step [60/497], Average Loss: 0.0167, Perplexity: 8.2661, Elapsed time: 746.4683s\n",
            "Epoch [2/10], Step [80/497], Average Loss: 0.0167, Perplexity: 8.2582, Elapsed time: 754.5313s\n",
            "Epoch [2/10], Step [100/497], Average Loss: 0.0167, Perplexity: 8.4681, Elapsed time: 762.7585s\n",
            "Epoch [2/10], Step [120/497], Average Loss: 0.0166, Perplexity: 8.5315, Elapsed time: 770.9265s\n",
            "Epoch [2/10], Step [140/497], Average Loss: 0.0166, Perplexity: 7.5445, Elapsed time: 779.1259s\n",
            "Epoch [2/10], Step [160/497], Average Loss: 0.0166, Perplexity: 8.2274, Elapsed time: 787.2228s\n",
            "Epoch [2/10], Step [180/497], Average Loss: 0.0166, Perplexity: 8.6627, Elapsed time: 795.3769s\n",
            "Epoch [2/10], Step [200/497], Average Loss: 0.0166, Perplexity: 8.4570, Elapsed time: 803.5515s\n",
            "Epoch [2/10], Step [220/497], Average Loss: 0.0166, Perplexity: 8.2238, Elapsed time: 811.8463s\n",
            "Epoch [2/10], Step [240/497], Average Loss: 0.0166, Perplexity: 9.0444, Elapsed time: 819.9116s\n",
            "Epoch [2/10], Step [260/497], Average Loss: 0.0166, Perplexity: 7.7808, Elapsed time: 828.2334s\n",
            "Epoch [2/10], Step [280/497], Average Loss: 0.0166, Perplexity: 8.7740, Elapsed time: 836.3197s\n",
            "Epoch [2/10], Step [300/497], Average Loss: 0.0166, Perplexity: 8.4032, Elapsed time: 844.3257s\n",
            "Epoch [2/10], Step [320/497], Average Loss: 0.0165, Perplexity: 7.9983, Elapsed time: 852.6103s\n",
            "Epoch [2/10], Step [340/497], Average Loss: 0.0165, Perplexity: 8.2912, Elapsed time: 860.9807s\n",
            "Epoch [2/10], Step [360/497], Average Loss: 0.0165, Perplexity: 8.2066, Elapsed time: 869.3250s\n",
            "Epoch [2/10], Step [380/497], Average Loss: 0.0165, Perplexity: 8.4208, Elapsed time: 877.4159s\n",
            "Epoch [2/10], Step [400/497], Average Loss: 0.0165, Perplexity: 8.6561, Elapsed time: 885.5404s\n",
            "Epoch [2/10], Step [420/497], Average Loss: 0.0165, Perplexity: 7.9066, Elapsed time: 893.7762s\n",
            "Epoch [2/10], Step [440/497], Average Loss: 0.0165, Perplexity: 7.6336, Elapsed time: 901.8701s\n",
            "Epoch [2/10], Step [460/497], Average Loss: 0.0164, Perplexity: 7.7256, Elapsed time: 909.9587s\n",
            "Epoch [2/10], Step [480/497], Average Loss: 0.0164, Perplexity: 7.5979, Elapsed time: 918.1524s\n",
            "Model saved: ./learned_models/InceptionV3/decoder-3.ckpt\n",
            "Model saved: ./learned_models/InceptionV3/encoder-3.ckpt\n",
            "[ Validation ]\n",
            "Epoch [2/10], Step [0/79], Average Loss: 0.0206, Perplexity: 13.9262, Elapsed time: 925.7862s\n",
            "Epoch [2/10], Step [20/79], Average Loss: 0.0212, Perplexity: 17.1262, Elapsed time: 933.8382s\n",
            "Epoch [2/10], Step [40/79], Average Loss: 0.0213, Perplexity: 16.0777, Elapsed time: 941.8272s\n",
            "Epoch [2/10], Step [60/79], Average Loss: 0.0212, Perplexity: 13.9639, Elapsed time: 949.5921s\n",
            "[ Training ]\n",
            "Epoch [3/10], Step [0/497], Average Loss: 0.0152, Perplexity: 7.0336, Elapsed time: 957.2363s\n",
            "Epoch [3/10], Step [20/497], Average Loss: 0.0151, Perplexity: 7.5265, Elapsed time: 965.2737s\n",
            "Epoch [3/10], Step [40/497], Average Loss: 0.0152, Perplexity: 7.4433, Elapsed time: 973.4746s\n",
            "Epoch [3/10], Step [60/497], Average Loss: 0.0151, Perplexity: 6.6580, Elapsed time: 981.5406s\n",
            "Epoch [3/10], Step [80/497], Average Loss: 0.0151, Perplexity: 7.1206, Elapsed time: 989.7161s\n",
            "Epoch [3/10], Step [100/497], Average Loss: 0.0151, Perplexity: 6.8450, Elapsed time: 998.0227s\n",
            "Epoch [3/10], Step [120/497], Average Loss: 0.0151, Perplexity: 6.5585, Elapsed time: 1006.2606s\n",
            "Epoch [3/10], Step [140/497], Average Loss: 0.0151, Perplexity: 7.2588, Elapsed time: 1014.4098s\n",
            "Epoch [3/10], Step [160/497], Average Loss: 0.0151, Perplexity: 7.2069, Elapsed time: 1022.4480s\n",
            "Epoch [3/10], Step [180/497], Average Loss: 0.0151, Perplexity: 7.0697, Elapsed time: 1030.4420s\n",
            "Epoch [3/10], Step [200/497], Average Loss: 0.0151, Perplexity: 6.4374, Elapsed time: 1038.8110s\n",
            "Epoch [3/10], Step [220/497], Average Loss: 0.0151, Perplexity: 7.0437, Elapsed time: 1046.8490s\n",
            "Epoch [3/10], Step [240/497], Average Loss: 0.0151, Perplexity: 6.6466, Elapsed time: 1054.9695s\n",
            "Epoch [3/10], Step [260/497], Average Loss: 0.0151, Perplexity: 6.7530, Elapsed time: 1063.2850s\n",
            "Epoch [3/10], Step [280/497], Average Loss: 0.0150, Perplexity: 6.7436, Elapsed time: 1071.4676s\n",
            "Epoch [3/10], Step [300/497], Average Loss: 0.0150, Perplexity: 6.8683, Elapsed time: 1079.5911s\n",
            "Epoch [3/10], Step [320/497], Average Loss: 0.0150, Perplexity: 6.8281, Elapsed time: 1087.6753s\n",
            "Epoch [3/10], Step [340/497], Average Loss: 0.0150, Perplexity: 6.7908, Elapsed time: 1095.7940s\n",
            "Epoch [3/10], Step [360/497], Average Loss: 0.0150, Perplexity: 6.4985, Elapsed time: 1103.9872s\n",
            "Epoch [3/10], Step [380/497], Average Loss: 0.0150, Perplexity: 6.6215, Elapsed time: 1111.9498s\n",
            "Epoch [3/10], Step [400/497], Average Loss: 0.0150, Perplexity: 6.2457, Elapsed time: 1120.0494s\n",
            "Epoch [3/10], Step [420/497], Average Loss: 0.0150, Perplexity: 6.8561, Elapsed time: 1128.1815s\n",
            "Epoch [3/10], Step [440/497], Average Loss: 0.0150, Perplexity: 5.9882, Elapsed time: 1136.5361s\n",
            "Epoch [3/10], Step [460/497], Average Loss: 0.0149, Perplexity: 6.1405, Elapsed time: 1144.6989s\n",
            "Epoch [3/10], Step [480/497], Average Loss: 0.0149, Perplexity: 7.1602, Elapsed time: 1152.9478s\n",
            "Model saved: ./learned_models/InceptionV3/decoder-4.ckpt\n",
            "Model saved: ./learned_models/InceptionV3/encoder-4.ckpt\n",
            "[ Validation ]\n",
            "Epoch [3/10], Step [0/79], Average Loss: 0.0210, Perplexity: 14.6219, Elapsed time: 1160.5582s\n",
            "Epoch [3/10], Step [20/79], Average Loss: 0.0214, Perplexity: 17.5914, Elapsed time: 1168.3244s\n",
            "Epoch [3/10], Step [40/79], Average Loss: 0.0215, Perplexity: 16.5367, Elapsed time: 1176.6419s\n",
            "Epoch [3/10], Step [60/79], Average Loss: 0.0215, Perplexity: 14.4472, Elapsed time: 1184.4675s\n",
            "[ Training ]\n",
            "Epoch [4/10], Step [0/497], Average Loss: 0.0140, Perplexity: 6.0379, Elapsed time: 1192.2541s\n",
            "Epoch [4/10], Step [20/497], Average Loss: 0.0136, Perplexity: 5.5994, Elapsed time: 1200.3655s\n",
            "Epoch [4/10], Step [40/497], Average Loss: 0.0136, Perplexity: 6.0638, Elapsed time: 1208.6286s\n",
            "Epoch [4/10], Step [60/497], Average Loss: 0.0136, Perplexity: 6.0706, Elapsed time: 1216.7110s\n",
            "Epoch [4/10], Step [80/497], Average Loss: 0.0136, Perplexity: 6.3191, Elapsed time: 1224.8724s\n",
            "Epoch [4/10], Step [100/497], Average Loss: 0.0136, Perplexity: 5.7242, Elapsed time: 1233.0222s\n",
            "Epoch [4/10], Step [120/497], Average Loss: 0.0136, Perplexity: 5.8741, Elapsed time: 1241.3405s\n",
            "Epoch [4/10], Step [140/497], Average Loss: 0.0136, Perplexity: 5.2818, Elapsed time: 1249.3683s\n",
            "Epoch [4/10], Step [160/497], Average Loss: 0.0136, Perplexity: 5.8183, Elapsed time: 1257.7935s\n",
            "Epoch [4/10], Step [180/497], Average Loss: 0.0137, Perplexity: 5.9759, Elapsed time: 1265.8876s\n",
            "Epoch [4/10], Step [200/497], Average Loss: 0.0137, Perplexity: 5.5563, Elapsed time: 1274.0635s\n",
            "Epoch [4/10], Step [220/497], Average Loss: 0.0136, Perplexity: 5.4724, Elapsed time: 1282.3125s\n",
            "Epoch [4/10], Step [240/497], Average Loss: 0.0136, Perplexity: 5.9250, Elapsed time: 1290.5615s\n",
            "Epoch [4/10], Step [260/497], Average Loss: 0.0136, Perplexity: 5.4697, Elapsed time: 1298.6971s\n",
            "Epoch [4/10], Step [280/497], Average Loss: 0.0136, Perplexity: 5.4222, Elapsed time: 1306.8284s\n",
            "Epoch [4/10], Step [300/497], Average Loss: 0.0136, Perplexity: 5.5455, Elapsed time: 1314.7721s\n",
            "Epoch [4/10], Step [320/497], Average Loss: 0.0136, Perplexity: 5.9338, Elapsed time: 1322.9692s\n",
            "Epoch [4/10], Step [340/497], Average Loss: 0.0136, Perplexity: 5.5833, Elapsed time: 1331.0630s\n",
            "Epoch [4/10], Step [360/497], Average Loss: 0.0136, Perplexity: 6.0416, Elapsed time: 1339.2542s\n",
            "Epoch [4/10], Step [380/497], Average Loss: 0.0136, Perplexity: 5.4544, Elapsed time: 1347.4843s\n",
            "Epoch [4/10], Step [400/497], Average Loss: 0.0136, Perplexity: 5.2667, Elapsed time: 1355.8171s\n",
            "Epoch [4/10], Step [420/497], Average Loss: 0.0136, Perplexity: 5.9442, Elapsed time: 1364.2146s\n",
            "Epoch [4/10], Step [440/497], Average Loss: 0.0136, Perplexity: 5.5118, Elapsed time: 1372.3019s\n",
            "Epoch [4/10], Step [460/497], Average Loss: 0.0136, Perplexity: 5.8193, Elapsed time: 1380.4904s\n",
            "Epoch [4/10], Step [480/497], Average Loss: 0.0136, Perplexity: 5.4843, Elapsed time: 1388.5939s\n",
            "Model saved: ./learned_models/InceptionV3/decoder-5.ckpt\n",
            "Model saved: ./learned_models/InceptionV3/encoder-5.ckpt\n",
            "[ Validation ]\n",
            "Epoch [4/10], Step [0/79], Average Loss: 0.0214, Perplexity: 15.5218, Elapsed time: 1396.3097s\n",
            "Epoch [4/10], Step [20/79], Average Loss: 0.0219, Perplexity: 18.8667, Elapsed time: 1404.1670s\n",
            "Epoch [4/10], Step [40/79], Average Loss: 0.0220, Perplexity: 17.1158, Elapsed time: 1412.0885s\n",
            "Epoch [4/10], Step [60/79], Average Loss: 0.0219, Perplexity: 14.7659, Elapsed time: 1420.0623s\n",
            "[ Training ]\n",
            "Epoch [5/10], Step [0/497], Average Loss: 0.0125, Perplexity: 4.9381, Elapsed time: 1428.0231s\n",
            "Epoch [5/10], Step [20/497], Average Loss: 0.0123, Perplexity: 4.7060, Elapsed time: 1436.1962s\n",
            "Epoch [5/10], Step [40/497], Average Loss: 0.0124, Perplexity: 5.1042, Elapsed time: 1444.2313s\n",
            "Epoch [5/10], Step [60/497], Average Loss: 0.0123, Perplexity: 4.8176, Elapsed time: 1452.3294s\n",
            "Epoch [5/10], Step [80/497], Average Loss: 0.0124, Perplexity: 5.1784, Elapsed time: 1460.5323s\n",
            "Epoch [5/10], Step [100/497], Average Loss: 0.0124, Perplexity: 4.7550, Elapsed time: 1468.6474s\n",
            "Epoch [5/10], Step [120/497], Average Loss: 0.0124, Perplexity: 4.8218, Elapsed time: 1476.8589s\n",
            "Epoch [5/10], Step [140/497], Average Loss: 0.0124, Perplexity: 4.7120, Elapsed time: 1485.2530s\n",
            "Epoch [5/10], Step [160/497], Average Loss: 0.0124, Perplexity: 4.6166, Elapsed time: 1493.6314s\n",
            "Epoch [5/10], Step [180/497], Average Loss: 0.0124, Perplexity: 4.7161, Elapsed time: 1501.8157s\n",
            "Epoch [5/10], Step [200/497], Average Loss: 0.0124, Perplexity: 4.9741, Elapsed time: 1510.0026s\n",
            "Epoch [5/10], Step [220/497], Average Loss: 0.0124, Perplexity: 5.0532, Elapsed time: 1518.2207s\n",
            "Epoch [5/10], Step [240/497], Average Loss: 0.0124, Perplexity: 4.8907, Elapsed time: 1526.3886s\n",
            "Epoch [5/10], Step [260/497], Average Loss: 0.0124, Perplexity: 5.0592, Elapsed time: 1534.4524s\n",
            "Epoch [5/10], Step [280/497], Average Loss: 0.0124, Perplexity: 4.9286, Elapsed time: 1542.5818s\n",
            "Epoch [5/10], Step [300/497], Average Loss: 0.0124, Perplexity: 5.0327, Elapsed time: 1550.7955s\n",
            "Epoch [5/10], Step [320/497], Average Loss: 0.0124, Perplexity: 4.7631, Elapsed time: 1559.0091s\n",
            "Epoch [5/10], Step [340/497], Average Loss: 0.0124, Perplexity: 4.9133, Elapsed time: 1567.1446s\n",
            "Epoch [5/10], Step [360/497], Average Loss: 0.0124, Perplexity: 4.7116, Elapsed time: 1575.3111s\n",
            "Epoch [5/10], Step [380/497], Average Loss: 0.0124, Perplexity: 5.0423, Elapsed time: 1583.5280s\n",
            "Epoch [5/10], Step [400/497], Average Loss: 0.0124, Perplexity: 4.6737, Elapsed time: 1591.7430s\n",
            "Epoch [5/10], Step [420/497], Average Loss: 0.0123, Perplexity: 4.6059, Elapsed time: 1599.9759s\n",
            "Epoch [5/10], Step [440/497], Average Loss: 0.0123, Perplexity: 4.6667, Elapsed time: 1608.2997s\n",
            "Epoch [5/10], Step [460/497], Average Loss: 0.0123, Perplexity: 4.6504, Elapsed time: 1616.6099s\n",
            "Epoch [5/10], Step [480/497], Average Loss: 0.0123, Perplexity: 4.6831, Elapsed time: 1624.8687s\n",
            "Model saved: ./learned_models/InceptionV3/decoder-6.ckpt\n",
            "Model saved: ./learned_models/InceptionV3/encoder-6.ckpt\n",
            "[ Validation ]\n",
            "Epoch [5/10], Step [0/79], Average Loss: 0.0218, Perplexity: 16.2982, Elapsed time: 1632.3665s\n",
            "Epoch [5/10], Step [20/79], Average Loss: 0.0224, Perplexity: 20.1993, Elapsed time: 1640.0479s\n",
            "Epoch [5/10], Step [40/79], Average Loss: 0.0225, Perplexity: 18.1047, Elapsed time: 1648.1519s\n",
            "Epoch [5/10], Step [60/79], Average Loss: 0.0225, Perplexity: 15.7654, Elapsed time: 1656.0617s\n",
            "[ Training ]\n",
            "Epoch [6/10], Step [0/497], Average Loss: 0.0111, Perplexity: 4.1296, Elapsed time: 1663.8163s\n",
            "Epoch [6/10], Step [20/497], Average Loss: 0.0112, Perplexity: 4.3707, Elapsed time: 1671.9891s\n",
            "Epoch [6/10], Step [40/497], Average Loss: 0.0112, Perplexity: 4.4442, Elapsed time: 1680.0044s\n",
            "Epoch [6/10], Step [60/497], Average Loss: 0.0112, Perplexity: 4.1157, Elapsed time: 1688.2199s\n",
            "Epoch [6/10], Step [80/497], Average Loss: 0.0112, Perplexity: 4.1493, Elapsed time: 1696.5352s\n",
            "Epoch [6/10], Step [100/497], Average Loss: 0.0112, Perplexity: 4.2059, Elapsed time: 1704.7828s\n",
            "Epoch [6/10], Step [120/497], Average Loss: 0.0112, Perplexity: 4.0754, Elapsed time: 1713.0370s\n",
            "Epoch [6/10], Step [140/497], Average Loss: 0.0112, Perplexity: 4.1604, Elapsed time: 1721.3925s\n",
            "Epoch [6/10], Step [160/497], Average Loss: 0.0113, Perplexity: 4.1050, Elapsed time: 1729.7017s\n",
            "Epoch [6/10], Step [180/497], Average Loss: 0.0113, Perplexity: 4.2161, Elapsed time: 1737.8875s\n",
            "Epoch [6/10], Step [200/497], Average Loss: 0.0113, Perplexity: 4.3012, Elapsed time: 1746.2093s\n",
            "Epoch [6/10], Step [220/497], Average Loss: 0.0113, Perplexity: 4.3928, Elapsed time: 1754.4564s\n",
            "Epoch [6/10], Step [240/497], Average Loss: 0.0113, Perplexity: 4.3485, Elapsed time: 1762.7506s\n",
            "Epoch [6/10], Step [260/497], Average Loss: 0.0113, Perplexity: 4.4456, Elapsed time: 1770.8916s\n",
            "Epoch [6/10], Step [280/497], Average Loss: 0.0113, Perplexity: 4.1638, Elapsed time: 1779.2460s\n",
            "Epoch [6/10], Step [300/497], Average Loss: 0.0113, Perplexity: 4.1468, Elapsed time: 1787.5615s\n",
            "Epoch [6/10], Step [320/497], Average Loss: 0.0113, Perplexity: 4.2181, Elapsed time: 1796.0618s\n",
            "Epoch [6/10], Step [340/497], Average Loss: 0.0113, Perplexity: 4.2884, Elapsed time: 1804.4380s\n",
            "Epoch [6/10], Step [360/497], Average Loss: 0.0113, Perplexity: 4.1733, Elapsed time: 1812.6902s\n",
            "Epoch [6/10], Step [380/497], Average Loss: 0.0113, Perplexity: 4.1508, Elapsed time: 1820.9648s\n",
            "Epoch [6/10], Step [400/497], Average Loss: 0.0113, Perplexity: 4.1046, Elapsed time: 1829.3033s\n",
            "Epoch [6/10], Step [420/497], Average Loss: 0.0113, Perplexity: 4.1627, Elapsed time: 1837.7435s\n",
            "Epoch [6/10], Step [440/497], Average Loss: 0.0113, Perplexity: 4.0011, Elapsed time: 1846.1854s\n",
            "Epoch [6/10], Step [460/497], Average Loss: 0.0113, Perplexity: 4.3209, Elapsed time: 1854.6829s\n",
            "Epoch [6/10], Step [480/497], Average Loss: 0.0112, Perplexity: 4.1346, Elapsed time: 1863.1945s\n",
            "Model saved: ./learned_models/InceptionV3/decoder-7.ckpt\n",
            "Model saved: ./learned_models/InceptionV3/encoder-7.ckpt\n",
            "[ Validation ]\n",
            "Epoch [6/10], Step [0/79], Average Loss: 0.0225, Perplexity: 17.9260, Elapsed time: 1871.1372s\n",
            "Epoch [6/10], Step [20/79], Average Loss: 0.0231, Perplexity: 22.9050, Elapsed time: 1879.2578s\n",
            "Epoch [6/10], Step [40/79], Average Loss: 0.0232, Perplexity: 20.0715, Elapsed time: 1887.4076s\n",
            "Epoch [6/10], Step [60/79], Average Loss: 0.0231, Perplexity: 17.3182, Elapsed time: 1895.3787s\n",
            "[ Training ]\n",
            "Epoch [7/10], Step [0/497], Average Loss: 0.0104, Perplexity: 3.7670, Elapsed time: 1903.3063s\n",
            "Epoch [7/10], Step [20/497], Average Loss: 0.0103, Perplexity: 3.7128, Elapsed time: 1911.6288s\n",
            "Epoch [7/10], Step [40/497], Average Loss: 0.0102, Perplexity: 4.0100, Elapsed time: 1919.9782s\n",
            "Epoch [7/10], Step [60/497], Average Loss: 0.0103, Perplexity: 3.8083, Elapsed time: 1928.6476s\n",
            "Epoch [7/10], Step [80/497], Average Loss: 0.0103, Perplexity: 3.7845, Elapsed time: 1936.9129s\n",
            "Epoch [7/10], Step [100/497], Average Loss: 0.0103, Perplexity: 3.7022, Elapsed time: 1945.2216s\n",
            "Epoch [7/10], Step [120/497], Average Loss: 0.0103, Perplexity: 3.7144, Elapsed time: 1953.6281s\n",
            "Epoch [7/10], Step [140/497], Average Loss: 0.0103, Perplexity: 3.6465, Elapsed time: 1962.1353s\n",
            "Epoch [7/10], Step [160/497], Average Loss: 0.0103, Perplexity: 3.9901, Elapsed time: 1970.6188s\n",
            "Epoch [7/10], Step [180/497], Average Loss: 0.0103, Perplexity: 3.8991, Elapsed time: 1979.2430s\n",
            "Epoch [7/10], Step [200/497], Average Loss: 0.0103, Perplexity: 3.9455, Elapsed time: 1987.6852s\n",
            "Epoch [7/10], Step [220/497], Average Loss: 0.0103, Perplexity: 3.8935, Elapsed time: 1996.1480s\n",
            "Epoch [7/10], Step [240/497], Average Loss: 0.0103, Perplexity: 3.8099, Elapsed time: 2004.4331s\n",
            "Epoch [7/10], Step [260/497], Average Loss: 0.0103, Perplexity: 3.7558, Elapsed time: 2012.8940s\n",
            "Epoch [7/10], Step [280/497], Average Loss: 0.0103, Perplexity: 3.7980, Elapsed time: 2021.5206s\n",
            "Epoch [7/10], Step [300/497], Average Loss: 0.0103, Perplexity: 3.6341, Elapsed time: 2029.9747s\n",
            "Epoch [7/10], Step [320/497], Average Loss: 0.0103, Perplexity: 3.5884, Elapsed time: 2038.3350s\n",
            "Epoch [7/10], Step [340/497], Average Loss: 0.0103, Perplexity: 3.5977, Elapsed time: 2046.8745s\n",
            "Epoch [7/10], Step [360/497], Average Loss: 0.0103, Perplexity: 3.8390, Elapsed time: 2055.4091s\n",
            "Epoch [7/10], Step [380/497], Average Loss: 0.0103, Perplexity: 3.7907, Elapsed time: 2063.7907s\n",
            "Epoch [7/10], Step [400/497], Average Loss: 0.0103, Perplexity: 3.7851, Elapsed time: 2072.0395s\n",
            "Epoch [7/10], Step [420/497], Average Loss: 0.0103, Perplexity: 3.6830, Elapsed time: 2080.4919s\n",
            "Epoch [7/10], Step [440/497], Average Loss: 0.0103, Perplexity: 3.8397, Elapsed time: 2088.9811s\n",
            "Epoch [7/10], Step [460/497], Average Loss: 0.0103, Perplexity: 3.7195, Elapsed time: 2097.4470s\n",
            "Epoch [7/10], Step [480/497], Average Loss: 0.0103, Perplexity: 3.6855, Elapsed time: 2106.0479s\n",
            "Model saved: ./learned_models/InceptionV3/decoder-8.ckpt\n",
            "Model saved: ./learned_models/InceptionV3/encoder-8.ckpt\n",
            "[ Validation ]\n",
            "Epoch [7/10], Step [0/79], Average Loss: 0.0233, Perplexity: 19.7844, Elapsed time: 2113.9709s\n",
            "Epoch [7/10], Step [20/79], Average Loss: 0.0238, Perplexity: 24.7610, Elapsed time: 2121.9176s\n",
            "Epoch [7/10], Step [40/79], Average Loss: 0.0239, Perplexity: 21.2080, Elapsed time: 2130.0888s\n",
            "Epoch [7/10], Step [60/79], Average Loss: 0.0238, Perplexity: 18.2669, Elapsed time: 2138.2608s\n",
            "[ Training ]\n",
            "Epoch [8/10], Step [0/497], Average Loss: 0.0095, Perplexity: 3.3673, Elapsed time: 2146.4555s\n",
            "Epoch [8/10], Step [20/497], Average Loss: 0.0094, Perplexity: 3.3270, Elapsed time: 2155.0346s\n",
            "Epoch [8/10], Step [40/497], Average Loss: 0.0094, Perplexity: 3.2943, Elapsed time: 2163.4968s\n",
            "Epoch [8/10], Step [60/497], Average Loss: 0.0094, Perplexity: 3.3969, Elapsed time: 2172.0660s\n",
            "Epoch [8/10], Step [80/497], Average Loss: 0.0095, Perplexity: 3.3242, Elapsed time: 2180.5518s\n",
            "Epoch [8/10], Step [100/497], Average Loss: 0.0095, Perplexity: 3.3937, Elapsed time: 2189.0428s\n",
            "Epoch [8/10], Step [120/497], Average Loss: 0.0095, Perplexity: 3.4224, Elapsed time: 2197.3259s\n",
            "Epoch [8/10], Step [140/497], Average Loss: 0.0095, Perplexity: 3.3030, Elapsed time: 2205.7147s\n",
            "Epoch [8/10], Step [160/497], Average Loss: 0.0095, Perplexity: 3.4480, Elapsed time: 2214.0780s\n",
            "Epoch [8/10], Step [180/497], Average Loss: 0.0095, Perplexity: 3.3440, Elapsed time: 2222.2924s\n",
            "Epoch [8/10], Step [200/497], Average Loss: 0.0095, Perplexity: 3.2978, Elapsed time: 2230.6435s\n",
            "Epoch [8/10], Step [220/497], Average Loss: 0.0095, Perplexity: 3.1062, Elapsed time: 2239.1732s\n",
            "Epoch [8/10], Step [240/497], Average Loss: 0.0095, Perplexity: 3.3695, Elapsed time: 2247.5434s\n",
            "Epoch [8/10], Step [260/497], Average Loss: 0.0095, Perplexity: 3.4773, Elapsed time: 2255.9728s\n",
            "Epoch [8/10], Step [280/497], Average Loss: 0.0095, Perplexity: 3.3723, Elapsed time: 2264.4115s\n",
            "Epoch [8/10], Step [300/497], Average Loss: 0.0095, Perplexity: 3.4081, Elapsed time: 2272.6838s\n",
            "Epoch [8/10], Step [320/497], Average Loss: 0.0095, Perplexity: 3.2761, Elapsed time: 2281.0728s\n",
            "Epoch [8/10], Step [340/497], Average Loss: 0.0095, Perplexity: 3.5256, Elapsed time: 2289.3803s\n",
            "Epoch [8/10], Step [360/497], Average Loss: 0.0095, Perplexity: 3.3118, Elapsed time: 2297.6676s\n",
            "Epoch [8/10], Step [380/497], Average Loss: 0.0095, Perplexity: 3.2381, Elapsed time: 2306.1581s\n",
            "Epoch [8/10], Step [400/497], Average Loss: 0.0095, Perplexity: 3.2787, Elapsed time: 2314.4021s\n",
            "Epoch [8/10], Step [420/497], Average Loss: 0.0095, Perplexity: 3.5511, Elapsed time: 2322.5834s\n",
            "Epoch [8/10], Step [440/497], Average Loss: 0.0095, Perplexity: 3.3873, Elapsed time: 2330.8965s\n",
            "Epoch [8/10], Step [460/497], Average Loss: 0.0095, Perplexity: 3.3288, Elapsed time: 2339.3463s\n",
            "Epoch [8/10], Step [480/497], Average Loss: 0.0095, Perplexity: 3.2757, Elapsed time: 2347.7136s\n",
            "Model saved: ./learned_models/InceptionV3/decoder-9.ckpt\n",
            "Model saved: ./learned_models/InceptionV3/encoder-9.ckpt\n",
            "[ Validation ]\n",
            "Epoch [8/10], Step [0/79], Average Loss: 0.0240, Perplexity: 21.4942, Elapsed time: 2355.5938s\n",
            "Epoch [8/10], Step [20/79], Average Loss: 0.0246, Perplexity: 27.7695, Elapsed time: 2363.7424s\n",
            "Epoch [8/10], Step [40/79], Average Loss: 0.0247, Perplexity: 23.4685, Elapsed time: 2372.1295s\n",
            "Epoch [8/10], Step [60/79], Average Loss: 0.0246, Perplexity: 20.2712, Elapsed time: 2380.1874s\n",
            "[ Training ]\n",
            "Epoch [9/10], Step [0/497], Average Loss: 0.0087, Perplexity: 3.0419, Elapsed time: 2388.0866s\n",
            "Epoch [9/10], Step [20/497], Average Loss: 0.0087, Perplexity: 3.1202, Elapsed time: 2396.3925s\n",
            "Epoch [9/10], Step [40/497], Average Loss: 0.0088, Perplexity: 2.9297, Elapsed time: 2404.6341s\n",
            "Epoch [9/10], Step [60/497], Average Loss: 0.0087, Perplexity: 3.0374, Elapsed time: 2413.0480s\n",
            "Epoch [9/10], Step [80/497], Average Loss: 0.0087, Perplexity: 3.0942, Elapsed time: 2421.6334s\n",
            "Epoch [9/10], Step [100/497], Average Loss: 0.0087, Perplexity: 2.9510, Elapsed time: 2429.9676s\n",
            "Epoch [9/10], Step [120/497], Average Loss: 0.0088, Perplexity: 3.0782, Elapsed time: 2438.3518s\n",
            "Epoch [9/10], Step [140/497], Average Loss: 0.0088, Perplexity: 3.0216, Elapsed time: 2446.6911s\n",
            "Epoch [9/10], Step [160/497], Average Loss: 0.0088, Perplexity: 3.0526, Elapsed time: 2454.9272s\n",
            "Epoch [9/10], Step [180/497], Average Loss: 0.0088, Perplexity: 3.2053, Elapsed time: 2463.1690s\n",
            "Epoch [9/10], Step [200/497], Average Loss: 0.0088, Perplexity: 3.2261, Elapsed time: 2471.5642s\n",
            "Epoch [9/10], Step [220/497], Average Loss: 0.0088, Perplexity: 3.0851, Elapsed time: 2479.9531s\n",
            "Epoch [9/10], Step [240/497], Average Loss: 0.0088, Perplexity: 3.1765, Elapsed time: 2488.1623s\n",
            "Epoch [9/10], Step [260/497], Average Loss: 0.0088, Perplexity: 3.2276, Elapsed time: 2496.6315s\n",
            "Epoch [9/10], Step [280/497], Average Loss: 0.0088, Perplexity: 3.1682, Elapsed time: 2505.0283s\n",
            "Epoch [9/10], Step [300/497], Average Loss: 0.0088, Perplexity: 3.1570, Elapsed time: 2513.3626s\n",
            "Epoch [9/10], Step [320/497], Average Loss: 0.0088, Perplexity: 3.0055, Elapsed time: 2521.6644s\n",
            "Epoch [9/10], Step [340/497], Average Loss: 0.0088, Perplexity: 3.1562, Elapsed time: 2530.0766s\n",
            "Epoch [9/10], Step [360/497], Average Loss: 0.0088, Perplexity: 2.9944, Elapsed time: 2538.4607s\n",
            "Epoch [9/10], Step [380/497], Average Loss: 0.0088, Perplexity: 2.9991, Elapsed time: 2546.8702s\n",
            "Epoch [9/10], Step [400/497], Average Loss: 0.0088, Perplexity: 3.1806, Elapsed time: 2555.1067s\n",
            "Epoch [9/10], Step [420/497], Average Loss: 0.0088, Perplexity: 3.1639, Elapsed time: 2563.4161s\n",
            "Epoch [9/10], Step [440/497], Average Loss: 0.0088, Perplexity: 3.1485, Elapsed time: 2571.4998s\n",
            "Epoch [9/10], Step [460/497], Average Loss: 0.0088, Perplexity: 3.1320, Elapsed time: 2579.9542s\n",
            "Epoch [9/10], Step [480/497], Average Loss: 0.0088, Perplexity: 3.3214, Elapsed time: 2588.1287s\n",
            "Model saved: ./learned_models/InceptionV3/decoder-10.ckpt\n",
            "Model saved: ./learned_models/InceptionV3/encoder-10.ckpt\n",
            "[ Validation ]\n",
            "Epoch [9/10], Step [0/79], Average Loss: 0.0247, Perplexity: 23.4682, Elapsed time: 2595.9120s\n",
            "Epoch [9/10], Step [20/79], Average Loss: 0.0253, Perplexity: 31.0657, Elapsed time: 2603.8996s\n",
            "Epoch [9/10], Step [40/79], Average Loss: 0.0254, Perplexity: 25.7681, Elapsed time: 2612.1344s\n",
            "Epoch [9/10], Step [60/79], Average Loss: 0.0254, Perplexity: 22.2513, Elapsed time: 2620.1016s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}